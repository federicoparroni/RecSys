{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-230fb09fd57a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportexport\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data'"
     ]
    }
   ],
   "source": [
    "import data.data as data\n",
    "import inout.importexport as imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import math\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from scipy.sparse import load_npz\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the complete dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the recommendations from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_recs = imp.importcsv('reranking/train_als_4coll_xgboost25_23-58-10.csv', check_len=-1)\n",
    "\n",
    "print(raw_recs[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explode each row into multiple rows (one per interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recs_tracks = []\n",
    "for rec in raw_recs:\n",
    "    playlist_id = rec[0]\n",
    "    for t in rec[1:]:\n",
    "        recs_tracks.append([playlist_id, t])\n",
    "recs_df = pd.DataFrame(recs_tracks, columns=['playlist_id','track_id'])\n",
    "\n",
    "print(recs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append the 'profile_length' column to the recommendation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ids = data.get_target_playlists()\n",
    "targetURM = data.get_urm_train_1()[target_ids]\n",
    "user_profile_lengths = np.array(targetURM.sum(axis=1)).flatten()\n",
    "profile_lengths_df = pd.DataFrame({'playlist_id': target_ids, 'profile_length': user_profile_lengths})\n",
    "\n",
    "print(profile_lengths_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rec_lengths_df = recs_df.merge(profile_lengths_df, on='playlist_id')\n",
    "print(rec_lengths_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Popularity feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = data.get_playlists_df()\n",
    "popularity = df.groupby(['track_id']).size().reset_index(name='popularity')\n",
    "print(popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rec_pop_df = rec_lengths_df.join(popularity.set_index('track_id'), on='track_id')\n",
    "print(rec_pop_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append the 'label' column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urm_test = data.get_urm_test_1()\n",
    "test_labels = []\n",
    "\n",
    "last_playlist_id = -1\n",
    "for idx,row in recs_df.iterrows():\n",
    "    current_playlist_id = row['playlist_id']\n",
    "    track_id = row['track_id']\n",
    "    # cache the row of the urm test if same playlist of the previous iteration\n",
    "    if not current_playlist_id == last_playlist_id:\n",
    "        # tracks ids in the t row of urm test\n",
    "        tracks_ids = urm_test.getrow(current_playlist_id).nonzero()[1]\n",
    "        last_playlist_id = current_playlist_id\n",
    "    \n",
    "    test_labels.append(1 if track_id in tracks_ids else 0)\n",
    "\n",
    "test_labels_df = pd.DataFrame({'label': test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rec_label_df = pd.concat([rec_pop_df, test_labels_df], axis=1)\n",
    "print(rec_label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [load_npz('raw_data/saved_r_hat_evaluation/4collaborative_l2.npz'), load_npz('raw_data/saved_r_hat_evaluation/als_l2.npz')]\n",
    "scores = [[], []]\n",
    "n = len(matrix)\n",
    "for idx,row in rec_label_df.iterrows():\n",
    "    for i in range(len(matrix)):\n",
    "        scores[i].append(matrix[i][row['playlist_id'], row['track_id']])\n",
    "\n",
    "dfn1 = pd.DataFrame({'score_4_coll': scores[0]/max(scores[0])})\n",
    "dfn2 = pd.DataFrame({'score_als': scores[1]/max(scores[1])})\n",
    "rec_scores_df = pd.concat([rec_label_df, dfn1, dfn2], axis=1)\n",
    "print(rec_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del matrix\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append the tracks features (album, artist, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = data.get_tracks_df()\n",
    "rec_feature_track_df = rec_scores_df.join(tdf.set_index('track_id'), on='track_id')\n",
    "print(rec_feature_track_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'm happy with the features gathered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full = rec_feature_track_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    n = x['label'].sum()\n",
    "    ones = x.loc[x['label'] == 1]\n",
    "    zeros = x.loc[x['label'] == 0].sample(n)\n",
    "    return pd.concat([ones,zeros])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = data.get_target_playlists()\n",
    "train_tgt = random.sample(tgt, math.floor(len(tgt)*0.8))\n",
    "test_tgt = list(set(tgt) - set(train_tgt))\n",
    "train = full.loc[full['playlist_id'].isin(train_tgt)]\n",
    "test = full.loc[full['playlist_id'].isin(test_tgt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.groupby(['playlist_id'], as_index=False).apply(func)\n",
    "train = train.reset_index().drop(['level_0', 'level_1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_concat_train = []\n",
    "to_concat_test = []\n",
    "to_onehot = []\n",
    "to_drop = ['album_id', 'artist_id', 'track_id', 'playlist_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotize(full, df, str):\n",
    "    exp = full[str].unique()\n",
    "    print(len(exp))\n",
    "    df.loc[:, (str)] = df[str].astype(CategoricalDtype(categories = exp))\n",
    "    oh = pd.get_dummies(df[str], prefix=str).to_sparse(fill_value=0)\n",
    "    return oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name in to_onehot:\n",
    "    to_concat_train.append(onehotize(full, train, name))\n",
    "    to_concat_test.append(onehotize(full, test, name))\n",
    "    train = train.drop(name, axis=1)\n",
    "    test = test.drop(name, axis=1)\n",
    "to_concat_train.insert(0, train)\n",
    "to_concat_test.insert(0, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat(to_concat_train, axis=1)\n",
    "test = pd.concat(to_concat_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traind = train.copy()\n",
    "testd = test.copy()\n",
    "for j in to_drop:\n",
    "    traind = traind.drop(j, axis=1)\n",
    "    testd = testd.drop(j, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "label_train = traind.label\n",
    "trainu = traind.drop(['label'], axis=1)\n",
    "label_test = testd.label\n",
    "testu = testd.drop(['label'], axis=1)\n",
    "dtrain = xgb.DMatrix(trainu, label=label_train)\n",
    "dtest = xgb.DMatrix(testu, label=label_test)\n",
    "\n",
    "param = {'max_depth': 16, 'eta': 0.1, 'silent': 1, 'objective': 'binary:logistic',\n",
    "         'lambda': 2, 'alpha': 2, 'tree_method': 'auto', 'grow_policy':'lossguide', 'subsample': 0.5}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "num_round = 100\n",
    "model_trained = xgb.train(param, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained.save_model('0001.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model_trained.predict(xgb.DMatrix(testu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame({'score': ypred})\n",
    "df_boosted = pd.concat([test, df_preds], axis=1)\n",
    "def fu(x):\n",
    "    x = x.sort_values(by=['score'], ascending=False).head(10)\n",
    "    return np.concatenate((x.playlist_id.unique(), x.track_id.unique())).astype(np.int32)\n",
    "df_boosted_sorted = df_boosted.groupby(['playlist_id'], as_index=False).apply(fu)\n",
    "recs = list(df_boosted_sorted.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(recommendations, test_urm, at_k=10, verbose=True):\n",
    "    aps = 0.0\n",
    "    for r in recommendations:\n",
    "        row = test_urm.getrow(r[0]).indices\n",
    "        m = min(at_k, len(row))\n",
    "\n",
    "        ap = 0.0\n",
    "        n_elems_found = 0.0\n",
    "        for j in range(1, m+1):\n",
    "            if r[j] in row:\n",
    "                n_elems_found += 1\n",
    "                ap = ap + n_elems_found/j\n",
    "        if m > 0:\n",
    "            ap = ap/m\n",
    "            aps += ap\n",
    "\n",
    "    result = aps/len(recommendations)\n",
    "    if verbose:\n",
    "        print('MAP: {}'.format(result))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(recs, data.get_urm_test_1())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
